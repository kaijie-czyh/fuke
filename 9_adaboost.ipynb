{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def min_cost_for_trip(N, K, prices):\n",
    "    # 初始化dp数组，大小为N x (K+1)，初始值为无穷大\n",
    "    dp = [[float('inf')] * (K + 1) for _ in range(N)]\n",
    "    \n",
    "    # 第一天初始化\n",
    "    for j in range(1, K + 1):\n",
    "        dp[0][j] = j * prices[0]\n",
    "    \n",
    "    # 设置dp[0][0]为无穷大，表示第一天不能没有食物\n",
    "    dp[0][0] = float('inf')\n",
    "    \n",
    "    # 动态规划填表\n",
    "    for i in range(1, N):\n",
    "        for j in range(K + 1):  # 包括j = K的情况，尽管我们不会从dp[i-1][K+1]获取值\n",
    "            if j > 0:\n",
    "                dp[i][j] = min(dp[i][j], dp[i-1][j-1])  # 消耗一份食物\n",
    "            if j < K:  # 确保j+1不会超出范围\n",
    "                dp[i][j] = min(dp[i][j], dp[i-1][j+1] + prices[i])  # 购买一份食物\n",
    "    \n",
    "    # 找出最后一天的最小花费（忽略dp[N-1][0]，因为它表示没有食物）\n",
    "    min_cost = min(dp[N-1][1:])\n",
    "    \n",
    "    # 打印dp数组（可选，用于调试）\n",
    "    # print(dp)\n",
    "    \n",
    "    return min_cost if min_cost != float('inf') else -1  # -1 表示无解，即无法每天保证有食物\n",
    "\n",
    "# 示例\n",
    "N = 5  # 总天数\n",
    "K = 3  # 最大携带食物数量\n",
    "prices = [2, 3, 1, 4, 2]  # 补给站每天的食物价格\n",
    "\n",
    "print(min_cost_for_trip(N, K, prices))  # 输出最低花费"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import numpy as np  \n",
    "from package_py import AdaBoost9\n",
    "\n",
    "def evaluate_classifier_multiple_times(classifier, X, y, n_iterations=10,max_depth=1):  \n",
    "    all_accuracies = []  \n",
    "    all_f1_scores = []  \n",
    "  \n",
    "    for iteration in range(n_iterations):  \n",
    "        # 设置十折交叉验证，每次使用不同的random_state  \n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42 + iteration * 10)  # 使用迭代次数作为随机种子  \n",
    "        scores = []  \n",
    "        f1_scores_iter = []  \n",
    "  \n",
    "        # 遍历交叉验证的每一折  \n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(X)):  \n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]  \n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]  \n",
    "  \n",
    "            # 将pandas读取的数据转化为list形式\n",
    "            X_train = X_train.values.tolist()  \n",
    "            y_train = y_train.values.tolist()  \n",
    "            X_test = X_test.values.tolist()  \n",
    "            y_test = y_test.values.tolist()  \n",
    "           \n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "\n",
    "            # print('X_train',X_train)\n",
    "            # 创建并训练AdaBoost模型\n",
    "            ada = classifier.AdaBoost(n_estimators=10)\n",
    "            ada.fit(X_train, y_train)\n",
    "\n",
    "            # 在测试集上进行预测\n",
    "            y_pred = ada.predict(X_test)\n",
    "            y_pred+=1\n",
    "            # print('y_pred',y_pred,len(y_pred))\n",
    "            # print('y_test',y_test,len(y_test))\n",
    "            accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)  \n",
    "            f1 = f1_score(y_test, y_pred, average='macro')  \n",
    "            scores.append(accuracy)  \n",
    "            f1_scores_iter.append(f1)  \n",
    "        # print('y_test',y_test,len(y_test))\n",
    "        mean_accuracy = np.mean(scores)  \n",
    "        std_accuracy = np.std(scores)  \n",
    "        mean_f1 = np.mean(f1_scores_iter)  \n",
    "        print(f'第{iteration}次',mean_accuracy)  \n",
    "        all_accuracies.append(mean_accuracy)  \n",
    "        all_f1_scores.append(mean_f1)  \n",
    "  \n",
    "        # print(f\"Iteration {iteration + 1}: Mean Accuracy = {mean_accuracy:.4f}, Std Accuracy = {std_accuracy:.4f}, Mean F1 Score = {mean_f1:.4f}\")  \n",
    "\n",
    "    overall_mean_accuracy = np.mean(all_accuracies)  \n",
    "    overall_std_accuracy = np.std(all_accuracies)  \n",
    "    overall_mean_f1 = np.mean(all_f1_scores)  \n",
    "  \n",
    "    return overall_mean_accuracy, overall_std_accuracy, overall_mean_f1  \n",
    "  \n",
    "# # 示例调用  \n",
    "# # classifier_instance = YourClassifier()  # 替换为你的分类器实例  \n",
    "# # X = your_X_data  # 替换为你的特征数据  \n",
    "# # y = your_y_data  # 替换为你的标签数据  \n",
    "# # k = your_k_value  # 替换为你的k值  \n",
    "# # evaluate_classifier_multiple_times(classifier_instance, X, y, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0次 0.6642857142857144\n",
      "第1次 0.6822510822510822\n",
      "第2次 0.6733766233766234\n",
      "第3次 0.6956709956709958\n",
      "第4次 0.6497835497835498\n",
      "第5次 0.6818181818181819\n",
      "第6次 0.6625541125541126\n",
      "第7次 0.6731601731601733\n",
      "第8次 0.6861471861471861\n",
      "第9次 0.674025974025974\n",
      "data\\gla.xls \n",
      "  mean_accuracy: 0.674 std_accuracy: 0.012 f1: 0.588\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "from package_py import AdaBoost9\n",
    "\n",
    "    \n",
    "file_paths =[ \"data\\\\gla.xls\"]  # 实际文件路径\n",
    "# file_paths =[ \"data\\\\bal.xls\", \"data\\\\gla_lisan_result.xlsx\", \"data\\\\hay.xls\", \"data\\\\iri.xls\", \"data\\\\new.xls\", \"data\\\\win_lisan_result.xls\", \"data\\\\zoo.xls\"]  # 实际文件路径\n",
    "# mean_accuracys=[]\n",
    "for i in range(len(file_paths)):\n",
    "    file_path=file_paths[i]\n",
    "\n",
    "    data = pd.read_excel(file_path, header=None)  \n",
    "    # 将数据分为特征和标签  \n",
    "    X = data.iloc[:, :-1]  # 前n列是特征  \n",
    "    y = data.iloc[:, -1]   # 最后一列是分类标签  \n",
    "    \n",
    "    # 数据标准hua\n",
    "    scaler = StandardScaler()  \n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    \n",
    "    mean_accuracy,std_accuracy,f1=evaluate_classifier_multiple_times(AdaBoost9,X_scaled_df,y,n_iterations=10,max_depth=3)\n",
    "    # mean_accuracys.append(mean_accuracy)\n",
    "\n",
    "    # 使用 f-string 格式化输出  \n",
    "    print(f'{file_path} \\n  mean_accuracy: {mean_accuracy:.3f} std_accuracy: {std_accuracy:.3f} f1: {f1:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 486, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"d:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 132, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"d:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 505, in _validate_estimator\n",
      "    % self.base_estimator_.__class__.__name__\n",
      "ValueError: MLPClassifier doesn't support sample_weight.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "MLPClassifier doesn't support sample_weight.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20392\\503438287.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# 使用cross_val_predict获取所有折叠的预测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0my_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mada_boost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# 计算F1分数（macro平均）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         )\n\u001b[1;32m--> 966\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msplits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m     )\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 264\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 264\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m   1042\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;31m# Check parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Clear any previous fit results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\TF\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_validate_estimator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    503\u001b[0m             raise ValueError(\n\u001b[0;32m    504\u001b[0m                 \u001b[1;34m\"%s doesn't support sample_weight.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m                 \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m             )\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: MLPClassifier doesn't support sample_weight."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "# 文件路径列表\n",
    "file_paths = [r\"data\\win.xls\"]  # 你可以根据需要添加更多文件路径\n",
    "# # 文件路径列表\n",
    "# file_paths = [\n",
    "#     r\"data\\bal.xls\", r\"data\\gla.xls\", r\"data\\hay.xls\",\n",
    "#     r\"data\\iri.xls\", r\"data\\new_avoid_negtive.xls\", r\"data\\win.xls\", r\"data\\zoo.xls\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# 初始化结果字典（虽然在此示例中未使用，但保留以备后续扩展）\n",
    "results = {}\n",
    "\n",
    "# 对每个数据集进行十次十折交叉验证\n",
    "for file_path in file_paths:\n",
    "    # 读取Excel文件\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "    \n",
    "    # 分离特征和标签\n",
    "    X = df.iloc[:, :-1].values  # 特征\n",
    "    y = df.iloc[:, -1].values    # 标签，并转换为整数类型\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    # 创建弱学习器：决策树桩\n",
    "    base_estimator = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "    \n",
    "    # 创建AdaBoost分类器\n",
    "    ada_boost = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42, learning_rate=1.0)\n",
    "    \n",
    "    # 初始化用于存储每次交叉验证结果的列表\n",
    "    accuracies = []\n",
    "    f1_scores_list = []\n",
    "    \n",
    "    # 进行十次十折交叉验证\n",
    "    for i in range(10):\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42 + i * 10)\n",
    "        \n",
    "        # 使用交叉验证计算准确度\n",
    "        scores = cross_val_score(ada_boost, X, y, cv=kf, scoring='accuracy')\n",
    "        accuracies.append(scores.mean())\n",
    "        \n",
    "        # 使用cross_val_predict获取所有折叠的预测\n",
    "        y_preds = cross_val_predict(ada_boost, X, y, cv=kf)\n",
    "        \n",
    "        # 计算F1分数（macro平均）\n",
    "        f1_scores = f1_score(y, y_preds, average='macro')\n",
    "        f1_scores_list.append(f1_scores)\n",
    "        \n",
    "        # 打印当前迭代的准确度\n",
    "        print(f\"数据集{file_path}第{i+1}次十折准确度: {scores.mean()}\")\n",
    "    \n",
    "    # 计算十次交叉验证的平均准确度和F1分数\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_f1 = np.mean(f1_scores_list)\n",
    "    \n",
    "    # 打印数据集的平均准确度和F1分数\n",
    "    print(f\"数据集{file_path}平均准确度: {mean_accuracy}\")\n",
    "    print(f\"数据集{file_path}平均F1分数: {mean_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义epsilon_t的取值范围（不包括0和1）\n",
    "epsilon_t = np.linspace(0.01, 0.99, 400)\n",
    "\n",
    "# 计算alpha_t\n",
    "alpha_t = 0.5 * np.log((1 - epsilon_t) / epsilon_t)\n",
    "\n",
    "# 绘制图像\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epsilon_t, alpha_t, label=r'$\\alpha_t = \\frac{1}{2} \\ln\\left(\\frac{1 - \\epsilon_t}{\\epsilon_t}\\right)$')\n",
    "plt.xlabel(r'$\\epsilon_t$')\n",
    "plt.ylabel(r'$\\alpha_t$')\n",
    "plt.title(r'Plot of $\\alpha_t$ vs. $\\epsilon_t$')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(-10, 10)  # 设置y轴的显示范围，以便更好地观察函数的变化\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "w=np.ones(n)/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# 可以继续添加其他可用的弱学习器\n",
    "\n",
    "class AdaBoost(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100):\n",
    "        self.base_estimator = base_estimator  # 弱学习器类及其参数\n",
    "        self.n_estimators = n_estimators  # 弱学习器的数量\n",
    "        self.models = []  # 存储每个弱学习器\n",
    "        self.model_weights = []  # 存储每个弱学习器的权重\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        N, _ = X.shape  # 样本数量与特征数量\n",
    "        # 初始化样本权重，所有样本权重相同\n",
    "        w = np.ones(N) / N\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # 训练一个弱学习器\n",
    "            model = clone(self.base_estimator)  # 使用sklearn的clone函数来复制基学习器，避免在迭代中共享参数\n",
    "            model.fit(X, y, sample_weight=w)\n",
    "            y_pred = model.predict(X)\n",
    "\n",
    "            # 计算误差率\n",
    "            misclassified = (y_pred != y)\n",
    "            error = np.dot(w, misclassified) / np.sum(w)\n",
    "\n",
    "            # 如果误差率大于0.5，则丢弃当前学习器（虽然理论上不应该发生，但出于健壮性考虑）\n",
    "            if error > 0.5:\n",
    "                break\n",
    "\n",
    "            # 计算弱学习器的权重\n",
    "            alpha = 0.5 * np.log((1 - error) / (error + 1e-10))  # 添加小常数避免除以0\n",
    "\n",
    "            # 更新样本权重\n",
    "            w = w * np.exp(-alpha * y * y_pred)\n",
    "            w = w / np.sum(w)  # 归一化\n",
    "\n",
    "            # 保存弱学习器及其权重\n",
    "            self.models.append(model)\n",
    "            self.model_weights.append(alpha)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 初始化预测结果\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "\n",
    "        # 遍历所有弱学习器，根据权重进行投票\n",
    "        for model, alpha in zip(self.models, self.model_weights):\n",
    "            y_pred += alpha * model.predict(X)\n",
    "\n",
    "        # 根据符号决定最终分类\n",
    "        y_pred = np.sign(y_pred)\n",
    "\n",
    "        # 如果需要，将标签转换为0和1\n",
    "        # y_pred = np.where(y_pred > 0, 1, 0)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.base import clone  # 导入clone函数以复制基学习器\n",
    "\n",
    "    # 创建一个示例数据集\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "    y = np.where(y == 0, -1, 1)  # 将标签转换为-1和1\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 创建并训练AdaBoost模型，使用LogisticRegression作为弱学习器\n",
    "    ada = AdaBoost(base_estimator=LogisticRegression(max_iter=100, solver='liblinear'), n_estimators=50)\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    # 在测试集上进行预测\n",
    "    y_pred = ada.predict(X_test)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=100):\n",
    "        self.n_estimators = n_estimators  # 弱学习器的数量\n",
    "        self.models = []  # 存储每个弱学习器\n",
    "        self.model_weights = []  # 存储每个弱学习器的权重\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        N, _ = X.shape  # 样本数量与特征数量\n",
    "        # 初始化样本权重，所有样本权重相同\n",
    "        w = np.ones(N) / N\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # 训练一个弱学习器（决策树桩）\n",
    "            model = DecisionTreeClassifier(max_depth=1)\n",
    "            model.fit(X, y, sample_weight=w)\n",
    "            y_pred = model.predict(X)\n",
    "\n",
    "            # 计算误差率\n",
    "            misclassified = (y_pred != y)\n",
    "            error = np.dot(w, misclassified) / np.sum(w)\n",
    "\n",
    "            # 计算弱学习器的权重\n",
    "            alpha = 0.5 * np.log((1 - error) / (error + 1e-10))  # 添加小常数避免除以0\n",
    "\n",
    "            # 更新样本权重\n",
    "            w = w * np.exp(-alpha * y * y_pred)\n",
    "            w = w / np.sum(w)  # 归一化\n",
    "\n",
    "            # 保存弱学习器及其权重\n",
    "            self.models.append(model)\n",
    "            self.model_weights.append(alpha)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 初始化预测结果\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "\n",
    "        # 遍历所有弱学习器，根据权重进行投票\n",
    "        for model, alpha in zip(self.models, self.model_weights):\n",
    "            y_pred += alpha * model.predict(X)\n",
    "\n",
    "        # 根据符号决定最终分类\n",
    "        y_pred = np.sign(y_pred)\n",
    "\n",
    "        # 由于sklearn的y要求是+1或-1，所以我们需要进行转换\n",
    "        # 如果你的标签是0和1，可以在这里添加一步转换：y_pred = np.where(y_pred > 0, 1, 0)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # 创建一个示例数据集\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "    y = np.where(y == 0, -1, 1)  # 将标签转换为-1和1\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 创建并训练AdaBoost模型\n",
    "    ada = AdaBoost(n_estimators=50)\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    # 在测试集上进行预测\n",
    "    y_pred = ada.predict(X_test)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=50):\n",
    "        self.n_estimators = n_estimators  # 弱学习器的数量\n",
    "        self.models = []  # 存储每个弱学习器\n",
    "        self.model_weights = []  # 存储每个弱学习器的权重\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        N, _ = X.shape  # 样本数量与特征数量\n",
    "        # 初始化样本权重，所有样本权重相同\n",
    "        w = np.ones(N) / N\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # 训练一个弱学习器（决策树桩）\n",
    "            model = DecisionTreeClassifier(max_depth=1)\n",
    "            model.fit(X, y, sample_weight=w)\n",
    "            y_pred = model.predict(X)\n",
    "\n",
    "            # 计算误差率\n",
    "            misclassified = (y_pred != y)\n",
    "            error = np.dot(w, misclassified) / np.sum(w)\n",
    "\n",
    "            # 计算弱学习器的权重\n",
    "            alpha = 0.5 * np.log((1 - error) / (error + 1e-10))  # 添加小常数避免除以0\n",
    "\n",
    "            # 更新样本权重\n",
    "            w = w * np.exp(-alpha * y * y_pred)\n",
    "            w = w / np.sum(w)  # 归一化\n",
    "\n",
    "            # 保存弱学习器及其权重\n",
    "            self.models.append(model)\n",
    "            self.model_weights.append(alpha)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 初始化预测结果\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "\n",
    "        # 遍历所有弱学习器，根据权重进行投票\n",
    "        for model, alpha in zip(self.models, self.model_weights):\n",
    "            y_pred += alpha * model.predict(X)\n",
    "\n",
    "        # 根据符号决定最终分类\n",
    "        y_pred = np.sign(y_pred)\n",
    "\n",
    "        # 由于sklearn的y要求是+1或-1，所以我们需要进行转换\n",
    "        # 如果你的标签是0和1，可以在这里添加一步转换：y_pred = np.where(y_pred > 0, 1, 0)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # 创建一个示例数据集\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "    y = np.where(y == 0, -1, 1)  # 将标签转换为-1和1\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 创建并训练AdaBoost模型\n",
    "    ada = AdaBoost(n_estimators=50)\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    # 在测试集上进行预测\n",
    "    y_pred = ada.predict(X_test)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9786940180459596,\n",
       " 0.40030185042285094,\n",
       " 0.20379393950623495,\n",
       " 0.13480796492959607,\n",
       " 0.13839702595244313,\n",
       " 0.22576055005174556,\n",
       " 0.21301380229999947,\n",
       " 0.14428483153364097,\n",
       " 0.15920262280403294,\n",
       " 0.18890080505157053,\n",
       " 0.21117846328312398,\n",
       " 0.06150123260703644,\n",
       " 0.06789744598155734,\n",
       " 0.17361007953663693,\n",
       " 0.15956626907037133,\n",
       " 0.07183237379141841,\n",
       " 0.06483442468600625,\n",
       " 0.060881980195973524,\n",
       " 0.057384243356044966,\n",
       " 0.13340790531841099,\n",
       " 0.10836605493232108,\n",
       " 0.04389612255806674,\n",
       " 0.07236958319525849,\n",
       " 0.08934116884554397,\n",
       " 0.1718275542675311,\n",
       " 0.2016382470768929,\n",
       " 0.21421380290869022,\n",
       " 0.15406651579577263,\n",
       " 0.15854253100113336,\n",
       " 0.13137340510204046,\n",
       " 0.16405589902337372,\n",
       " 0.18772497505423202,\n",
       " 0.1121482970980514,\n",
       " 0.08264962723629503,\n",
       " 0.0714760599670678,\n",
       " 0.09950982379299729,\n",
       " 0.11562552887424575,\n",
       " 0.1340078209341261,\n",
       " 0.1299085021507696,\n",
       " 0.08535188945851153,\n",
       " 0.14636563791676868,\n",
       " 0.06396533999763084,\n",
       " 0.12179430752070383,\n",
       " 0.13880295493596087,\n",
       " 0.16201209490523946,\n",
       " 0.08388807861658354,\n",
       " 0.08946238087168704,\n",
       " 0.10833338111376709,\n",
       " 0.0849819816086901,\n",
       " 0.09713325842423243]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
