{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import numpy as np  \n",
    "\n",
    "\n",
    "def evaluate_classifier_multiple_times(classifier, X, y, n_iterations=10):  \n",
    "    all_accuracies = []  \n",
    "    all_f1_scores = []  \n",
    "  \n",
    "    for iteration in range(n_iterations):  \n",
    "        # 设置十折交叉验证，每次使用不同的random_state  \n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42 + iteration * 10)  # 使用迭代次数作为随机种子  \n",
    "        scores = []  \n",
    "        f1_scores_iter = []  \n",
    "  \n",
    "        # 遍历交叉验证的每一折  \n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(X)):  \n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]  \n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]  \n",
    "  \n",
    "            # 将pandas读取的数据转化为list形式\n",
    "            X_train = X_train.values.tolist()  \n",
    "            y_train = y_train.values.tolist()  \n",
    "            # X_test = X_test.values.tolist()  \n",
    "            y_test = y_test.values.tolist()  \n",
    "           \n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "\n",
    "            nn = classifier.NeuralNetworks(X_train,y_train)\n",
    "            W1, b1, W2, b2 = nn.fit(activation='relu')\n",
    "            # print('训练后参数',lr.theta)\n",
    "            y_pred=nn.predict(X_test, activation='relu')\n",
    "            \n",
    "            # one_hot索引原坐标问题，本预测要求，数据集标签从1开始，而预测的标签从0开始且连续不间断，所以预测的标签需要+1\n",
    "            # Original Labels: [0 2 1 2 0]\n",
    "            # One-Hot Encoded Labels:\n",
    "            # [[1. 0. 0.]\n",
    "            # [0. 0. 1.]\n",
    "            y_pred=y_pred+1\n",
    "            # print('y_pred',y_pred,len(y_pred))\n",
    "            # print('y_test',y_test,len(y_test))\n",
    "            accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)  \n",
    "            f1 = f1_score(y_test, y_pred, average='macro')  \n",
    "            scores.append(accuracy)  \n",
    "            f1_scores_iter.append(f1)  \n",
    "  \n",
    "        mean_accuracy = np.mean(scores)  \n",
    "        std_accuracy = np.std(scores)  \n",
    "        mean_f1 = np.mean(f1_scores_iter)  \n",
    "        print(f'第{iteration}次',mean_accuracy)  \n",
    "        all_accuracies.append(mean_accuracy)  \n",
    "        all_f1_scores.append(mean_f1)  \n",
    "  \n",
    "        # print(f\"Iteration {iteration + 1}: Mean Accuracy = {mean_accuracy:.4f}, Std Accuracy = {std_accuracy:.4f}, Mean F1 Score = {mean_f1:.4f}\")  \n",
    "\n",
    "    overall_mean_accuracy = np.mean(all_accuracies)  \n",
    "    overall_std_accuracy = np.std(all_accuracies)  \n",
    "    overall_mean_f1 = np.mean(all_f1_scores)  \n",
    "  \n",
    "    return overall_mean_accuracy, overall_std_accuracy, overall_mean_f1  \n",
    "  \n",
    "# # 示例调用  \n",
    "# # classifier_instance = YourClassifier()  # 替换为你的分类器实例  \n",
    "# # X = your_X_data  # 替换为你的特征数据  \n",
    "# # y = your_y_data  # 替换为你的标签数据  \n",
    "# # k = your_k_value  # 替换为你的k值  \n",
    "# # evaluate_classifier_multiple_times(classifier_instance, X, y, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0次 0.775\n",
      "第1次 0.75\n",
      "第2次 0.7625\n",
      "第3次 0.71875\n",
      "第4次 0.74375\n",
      "第5次 0.7375\n",
      "第6次 0.78125\n",
      "第7次 0.775\n",
      "第8次 0.75625\n",
      "第9次 0.73125\n",
      "data\\hay.xls \n",
      "  mean_accuracy: 0.753 std_accuracy: 0.020 f1: 0.749\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from package_py import NeuralNetworks7\n",
    "\n",
    "    \n",
    "file_paths =[ \"data\\\\hay.xls\"]  # 实际文件路径\n",
    "# file_paths =[ \"data\\\\bal.xls\", \"data\\\\gla.xls\", \"data\\\\hay.xls\", \"data\\\\iri.xls\", \"data\\\\new.xls\", \"data\\\\win.xls\", \"data\\\\zoo.xls\"]  # 实际文件路径\n",
    "# mean_accuracys=[]\n",
    "for i in range(len(file_paths)):\n",
    "    file_path=file_paths[i]\n",
    "\n",
    "    data = pd.read_excel(file_path, header=None)  \n",
    "    # 将数据分为特征和标签  \n",
    "    X = data.iloc[:, :-1]  # 前n列是特征  \n",
    "    y = data.iloc[:, -1]   # 最后一列是分类标签  \n",
    "    \n",
    "    # 数据标准hua\n",
    "    scaler = StandardScaler()  \n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    \n",
    "    mean_accuracy,std_accuracy,f1=evaluate_classifier_multiple_times(NeuralNetworks7,X_scaled_df,y,10)\n",
    "    # mean_accuracys.append(mean_accuracy)\n",
    "\n",
    "    # 使用 f-string 格式化输出  \n",
    "    print(f'{file_path} \\n  mean_accuracy: {mean_accuracy:.3f} std_accuracy: {std_accuracy:.3f} f1: {f1:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集data\\win.xls第1次十折准确度: 0.8258169934640522\n",
      "数据集data\\win.xls第2次十折准确度: 0.7065359477124183\n",
      "数据集data\\win.xls第3次十折准确度: 0.6767973856209151\n",
      "数据集data\\win.xls第4次十折准确度: 0.7575163398692809\n",
      "数据集data\\win.xls第5次十折准确度: 0.7509803921568627\n",
      "数据集data\\win.xls第6次十折准确度: 0.6594771241830066\n",
      "数据集data\\win.xls第7次十折准确度: 0.6954248366013072\n",
      "数据集data\\win.xls第8次十折准确度: 0.7284313725490196\n",
      "数据集data\\win.xls第9次十折准确度: 0.6186274509803923\n",
      "数据集data\\win.xls第10次十折准确度: 0.7859477124183007\n",
      "数据集data\\win.xls平均准确度: 0.7205555555555556\n",
      "数据集data\\win.xls平均F1分数: 0.6993545787834976\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neural_network import MLPClassifier  # 使用多层感知器（神经网络）\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "# 文件路径列表\n",
    "file_paths = [r\"data\\win.xls\"]  # 你可以根据需要添加更多文件路径\n",
    "# # 文件路径列表\n",
    "# file_paths = [\n",
    "#     r\"data\\bal.xls\", r\"data\\gla.xls\", r\"data\\hay.xls\",\n",
    "#     r\"data\\iri.xls\", r\"data\\new_avoid_negtive.xls\", r\"data\\win.xls\", r\"data\\zoo.xls\"\n",
    "# ]\n",
    "\n",
    "# 初始化结果字典\n",
    "results = {}\n",
    "\n",
    "# 对每个数据集进行十次十折交叉验证\n",
    "for file_path in file_paths:\n",
    "    # 读取Excel文件\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "    \n",
    "    # 分离特征和标签\n",
    "    X = df.iloc[:, :-1].values  # 将数据转换为NumPy数组，所有行，除了最后一列的所有列（特征）\n",
    "    y = df.iloc[:, -1].values    # 将数据转换为NumPy数组，所有行，最后一列（标签）\n",
    "    \n",
    "    # 确保标签是整数类型（对于sklearn的分类器通常是必要的）\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    # 创建多层感知器分类器（神经网络）\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42, solver='adam', learning_rate_init=0.01)\n",
    "    # hidden_layer_sizes定义了一个隐藏层，包含100个神经元；max_iter增加以避免收敛警告；solver选择'adam'进行优化\n",
    "    \n",
    "    # 初始化用于存储每次交叉验证结果的列表\n",
    "    accuracies = []\n",
    "    f1_scores_list = []\n",
    "    \n",
    "    # 进行十次十折交叉验证\n",
    "    for i in range(10):\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42 + i * 10)\n",
    "        scores = cross_val_score(mlp, X, y, cv=kf, scoring='accuracy')\n",
    "        accuracies.append(scores.mean())\n",
    "        \n",
    "        # 使用cross_val_predict获取所有折叠的预测\n",
    "        y_preds = cross_val_predict(mlp, X, y, cv=kf)\n",
    "        \n",
    "        # 计算F1分数（macro平均）\n",
    "        f1_scores = f1_score(y, y_preds, average='macro')\n",
    "        f1_scores_list.append(f1_scores)\n",
    "        print(f\"数据集{file_path}第{i+1}次十折准确度: {scores.mean()}\")\n",
    "    \n",
    "    # 计算十次交叉验证的平均准确度和F1分数\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_f1 = np.mean(f1_scores_list)\n",
    "    print(f\"数据集{file_path}平均准确度: {mean_accuracy}\")\n",
    "    print(f\"数据集{file_path}平均F1分数: {mean_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5351582268907642\n",
      "Epoch 100, Loss: 0.2927935920643684\n",
      "Epoch 200, Loss: 0.20486953535773558\n",
      "Epoch 300, Loss: 0.16515315875573516\n",
      "Epoch 400, Loss: 0.13943172664081677\n",
      "Epoch 500, Loss: 0.12043535752130399\n",
      "Epoch 600, Loss: 0.10587705457041215\n",
      "Epoch 700, Loss: 0.09461338156360523\n",
      "Epoch 800, Loss: 0.08538831420687877\n",
      "Epoch 900, Loss: 0.07803506211895396\n",
      "Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 激活函数及其导数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "# 初始化参数\n",
    "def initialize_parameters(input_dim, hidden_dim, output_dim):\n",
    "    np.random.seed(42)\n",
    "    W1 = np.random.randn(input_dim, hidden_dim) * np.sqrt(2. / input_dim)\n",
    "    b1 = np.zeros((1, hidden_dim))\n",
    "    W2 = np.random.randn(hidden_dim, output_dim) * np.sqrt(2. / hidden_dim)\n",
    "    b2 = np.zeros((1, output_dim))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# 前向传播\n",
    "def forward_propagation(X, W1, b1, W2, b2, activation='relu'):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    if activation == 'relu':\n",
    "        A1 = relu(Z1)\n",
    "    elif activation == 'sigmoid':\n",
    "        A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)  # 输出层使用 sigmoid\n",
    "    return A1, A2\n",
    "\n",
    "# 计算损失（交叉熵损失）\n",
    "def compute_loss(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1. - epsilon)\n",
    "   \n",
    "    log_likelihood = -np.log(y_pred[y_true == 1])\n",
    "\n",
    "\n",
    "    # log_likelihood = -np.log(y_pred[range(m), y_true])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n",
    "\n",
    "# 反向传播\n",
    "def backward_propagation(X, y, A1, A2, W1, W2, activation='relu'):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # 输出层误差\n",
    "    dZ2 = A2 - y\n",
    "    dW2 = (1 / m) * np.dot(A1.T, dZ2)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=0, keepdims=True)\n",
    "    \n",
    "    # 隐藏层误差\n",
    "    if activation == 'relu':\n",
    "        dA1 = np.dot(dZ2, W2.T) * relu_derivative(A1)\n",
    "    elif activation == 'sigmoid':\n",
    "        dA1 = np.dot(dZ2, W2.T) * sigmoid_derivative(A1)\n",
    "    dZ1 = dA1\n",
    "    dW1 = (1 / m) * np.dot(X.T, dZ1)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=0, keepdims=True)\n",
    "    \n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# 更新参数\n",
    "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# 训练模型\n",
    "def train(X, y, input_dim, hidden_dim, output_dim, epochs, learning_rate, activation='relu'):\n",
    "    W1, b1, W2, b2 = initialize_parameters(input_dim, hidden_dim, output_dim)\n",
    "    for epoch in range(epochs):\n",
    "        A1, A2 = forward_propagation(X, W1, b1, W2, b2, activation)\n",
    "        # print(A2.shape)\n",
    "        # print(y.shape)\n",
    "        loss = compute_loss(y, A2)\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss}')\n",
    "        dW1, db1, dW2, db2 = backward_propagation(X, y, A1, A2, W1, W2, activation)\n",
    "        W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# 预测\n",
    "def predict(X, W1, b1, W2, b2, activation='relu'):\n",
    "    A1, A2 = forward_propagation(X, W1, b1, W2, b2, activation)\n",
    "    y_pred = np.argmax(A2, axis=1)\n",
    "    return y_pred\n",
    "\n",
    "# 生成数据\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 2)\n",
    "y = (X[:, 0] + X[:, 1] > 0).astype(int)  # 简单的线性分类\n",
    "y = y.reshape(-1, 1)  # 确保 y 的形状为 (n_samples, 1)\n",
    "\n",
    "# 标准化数据\n",
    "X_mean = np.mean(X, axis=0)\n",
    "X_std = np.std(X, axis=0)\n",
    "X = (X - X_mean) / X_std\n",
    "\n",
    "# 训练模型\n",
    "input_dim = 2\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "W1, b1, W2, b2 = train(X, y, input_dim, hidden_dim, output_dim, epochs, learning_rate, activation='relu')\n",
    "\n",
    "# 测试模型\n",
    "y_pred = predict(X, W1, b1, W2, b2, activation='relu')\n",
    "accuracy = np.mean(y_pred == y)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.18619012e-01 -1.73352446e-01]\n",
      " [ 8.95814650e-01  1.49821901e+00]\n",
      " [-1.39185696e-01 -2.69818200e-01]\n",
      " [ 1.98912620e+00  7.37949528e-01]\n",
      " [-4.15377295e-01  5.11683696e-01]\n",
      " [-4.08268674e-01 -5.02843704e-01]\n",
      " [ 4.19621786e-01 -1.95934920e+00]\n",
      " [-1.88886634e+00 -5.99998817e-01]\n",
      " [-1.05310431e+00  2.81958570e-01]\n",
      " [-9.30094359e-01 -1.45527346e+00]\n",
      " [ 1.85583833e+00 -2.61405822e-01]\n",
      " [ 2.14891985e-01 -1.46779493e+00]\n",
      " [-5.03295725e-01  7.73759949e-02]\n",
      " [-1.21526284e+00  3.43789409e-01]\n",
      " [-5.69322234e-01 -3.27731058e-01]\n",
      " [-5.70575634e-01  1.82950417e+00]\n",
      " [ 1.19794047e-01 -1.09848706e+00]\n",
      " [ 1.10104010e+00 -1.26262898e+00]\n",
      " [ 3.80774526e-01 -2.00602607e+00]\n",
      " [-1.42323013e+00  1.63846285e-01]\n",
      " [ 1.00235904e+00  1.38195623e-01]\n",
      " [-9.86215258e-05 -3.37199217e-01]\n",
      " [-1.59967644e+00 -7.58530192e-01]\n",
      " [-4.05007109e-01  1.02942912e+00]\n",
      " [ 5.38933436e-01 -1.80817968e+00]\n",
      " [ 5.16006392e-01 -4.21697320e-01]\n",
      " [-6.58854441e-01  5.81227516e-01]\n",
      " [ 1.34569914e+00  9.02808518e-01]\n",
      " [-8.49337475e-01 -3.45358060e-01]\n",
      " [ 5.24432784e-01  9.47347363e-01]\n",
      " [-4.26761818e-01 -2.21040320e-01]\n",
      " [-1.16284792e+00 -1.23783954e+00]\n",
      " [ 1.08928090e+00  1.33039737e+00]\n",
      " [ 5.11186215e-02  9.75508276e-01]\n",
      " [ 5.60080495e-01 -6.83343469e-01]\n",
      " [ 5.59798319e-01  1.51331855e+00]\n",
      " [ 9.35871607e-02  1.54009024e+00]\n",
      " [-2.93910735e+00  7.92754258e-01]\n",
      " [ 2.37800887e-01 -3.35089903e-01]\n",
      " [ 2.43333273e-01 -2.03409745e+00]\n",
      " [-1.22189062e-01  3.25088987e-01]\n",
      " [ 1.87021037e+00 -5.55709201e-01]\n",
      " [-8.13277419e-01 -5.39093870e-01]\n",
      " [ 1.21002476e+00  2.96552072e-01]\n",
      " [-4.86133562e-01  4.82209872e-01]\n",
      " [ 2.49573464e-01  9.40404540e-01]\n",
      " [-6.88350307e-01 -3.63921967e-01]\n",
      " [-3.24574083e-01 -1.50680152e+00]\n",
      " [ 4.83185962e-01  2.28437446e-01]\n",
      " [ 1.41637034e-01 -2.70271162e-01]\n",
      " [-1.52555707e+00 -4.57480367e-01]\n",
      " [-2.66601753e-01 -8.41473210e-01]\n",
      " [-5.36623662e-02  3.72317647e-01]\n",
      " [ 2.34941442e+00  1.41425010e-01]\n",
      " [ 4.37917252e-01 -1.09139259e-01]\n",
      " [-2.11638821e+00 -6.09106962e-02]\n",
      " [ 2.06326473e-01  2.44424772e+00]\n",
      " [-9.01347739e-02  2.69180013e-01]\n",
      " [ 9.48949566e-02 -1.21014065e+00]\n",
      " [ 1.47694392e+00  7.22351933e-01]\n",
      " [ 1.06405396e+00 -9.49246013e-01]\n",
      " [ 1.78206730e+00 -1.44475616e+00]\n",
      " [ 8.24417992e-01  2.16977369e+00]\n",
      " [-1.02693735e+00 -6.04033826e-01]\n",
      " [ 2.52594300e-01 -5.40823113e-01]\n",
      " [-1.68434741e+00  3.47543299e-02]\n",
      " [-1.11116931e+00  4.42289427e-01]\n",
      " [-9.43474499e-01  1.52529000e+00]\n",
      " [-7.83653368e-01 -3.58286689e-01]\n",
      " [ 1.09044448e+00 -1.27271163e+00]\n",
      " [ 4.02600681e-01  1.28099636e+00]\n",
      " [-1.75103569e+00  1.51543265e-01]\n",
      " [ 4.40654748e-01  7.52426680e-01]\n",
      " [-1.31614902e+00 -1.36285818e+00]\n",
      " [ 7.48227925e-01  2.64589118e-01]\n",
      " [ 4.29633957e-01  3.14358651e-01]\n",
      " [-6.62496044e-01  1.99457695e-01]\n",
      " [ 4.79608815e-01 -7.53003421e-01]\n",
      " [ 2.32545797e+00  4.42531405e-01]\n",
      " [-1.26257379e+00  6.26382462e-01]\n",
      " [-1.00832905e+00  7.57720963e-01]\n",
      " [ 1.49545610e+00 -8.59992119e-01]\n",
      " [ 1.26633091e+00  3.81101724e-01]\n",
      " [ 1.10047116e+00  1.87429435e+00]\n",
      " [-1.52371689e-01 -7.92631814e-01]\n",
      " [-9.08369955e-01 -8.55089945e-01]\n",
      " [ 4.51427259e-02  3.09029652e-01]\n",
      " [ 4.60381970e-01  7.98067671e-01]\n",
      " [ 1.50895534e-01  1.42829331e+00]\n",
      " [-1.74986999e-01  2.70276420e+00]\n",
      " [ 8.69968816e-01 -8.96693004e-01]\n",
      " [-1.12124979e+00  4.51224346e-01]\n",
      " [-1.26638363e-01  6.84184732e-01]\n",
      " [ 6.91065076e-01 -1.07512253e-01]\n",
      " [-8.58229504e-01 -1.55845135e+00]\n",
      " [-3.88430263e-01  8.27463953e-01]\n",
      " [ 3.86913049e-01 -1.28767811e+00]\n",
      " [ 3.38894486e-01  3.53468279e-01]\n",
      " [-9.01730454e-01  1.20443301e-01]\n",
      " [ 2.03953889e-01 -1.18427387e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 生成一些简单的二维数据\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 2)\n",
    "y = (X[:, 0] + X[:, 1] > 0).astype(int)  # 简单的线性分类\n",
    "\n",
    "# 标准化数据\n",
    "X_mean = np.mean(X, axis=0)\n",
    "X_std = np.std(X, axis=0)\n",
    "X = (X - X_mean) / X_std\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(input_dim, hidden_dim, output_dim):\n",
    "    np.random.seed(42)\n",
    "    W1 = np.random.randn(input_dim, hidden_dim) * np.sqrt(2. / input_dim)\n",
    "    b1 = np.zeros((1, hidden_dim))\n",
    "    W2 = np.random.randn(hidden_dim, output_dim) * np.sqrt(2. / hidden_dim)\n",
    "    b2 = np.zeros((1, output_dim))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, W1, b1, W2, b2, activation='relu'):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    if activation == 'relu':\n",
    "        A1 = relu(Z1)\n",
    "    elif activation == 'sigmoid':\n",
    "        A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)  # 输出层通常使用 sigmoid 或 softmax\n",
    "    return A1, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算多类别交叉熵损失函数\n",
    "\n",
    "    参数:\n",
    "    y_true (ndarray): 形状为 (m, k) 的真实标签，其中 m 是样本数量，k 是类别数量\n",
    "    y_pred (ndarray): 形状为 (m, k) 的预测概率，其中 m 是样本数量，k 是类别数量\n",
    "\n",
    "    返回:\n",
    "    loss (float): 计算得到的损失值\n",
    "    \"\"\"\n",
    "    # 获取样本数量\n",
    "    m = y_true.shape[0]\n",
    "    # 定义一个极小值，用于避免对数计算中的除以零错误\n",
    "    epsilon = 1e-15\n",
    "    # 将预测概率限制在 [epsilon, 1 - epsilon] 区间内，以避免对数计算中的无穷大\n",
    "    y_pred = np.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    # 计算每个样本的对数似然损失\n",
    "    log_likelihood = -np.log(y_pred[range(m), y_true.flatten()])\n",
    "    # 计算平均损失\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, y, A1, A2, W1, W2, activation='relu'):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # 输出层误差\n",
    "    dZ2 = A2 - y\n",
    "    dW2 = (1 / m) * np.dot(A1.T, dZ2)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=0, keepdims=True)\n",
    "    \n",
    "    # 隐藏层误差\n",
    "    if activation == 'relu':\n",
    "        dA1 = np.dot(dZ2, W2.T) * relu_derivative(A1)\n",
    "    elif activation == 'sigmoid':\n",
    "        dA1 = np.dot(dZ2, W2.T) * sigmoid_derivative(A1)\n",
    "    dZ1 = dA1\n",
    "    dW1 = (1 / m) * np.dot(X.T, dZ1)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=0, keepdims=True)\n",
    "    \n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, input_dim, hidden_dim, output_dim, epochs, learning_rate, activation='relu'):\n",
    "    W1, b1, W2, b2 = initialize_parameters(input_dim, hidden_dim, output_dim)\n",
    "    for epoch in range(epochs):\n",
    "        A1, A2 = forward_propagation(X, W1, b1, W2, b2, activation)\n",
    "        loss = compute_loss(y, A2)\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss}')\n",
    "        dW1, db1, dW2, db2 = backward_propagation(X, y, A1, A2, W1, W2, activation)\n",
    "        W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20368\\4061954224.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# 测试模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20368\\412087996.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(X, y, input_dim, hidden_dim, output_dim, epochs, learning_rate, activation)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mA1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch {epoch}, Loss: {loss}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20368\\2520658288.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mlog_likelihood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "def predict(X, W1, b1, W2, b2, activation='relu'):\n",
    "    A1, A2 = forward_propagation(X, W1, b1, W2, b2, activation)\n",
    "    y_pred = np.argmax(A2, axis=1)\n",
    "    return y_pred\n",
    "\n",
    "# 训练模型\n",
    "input_dim = 2\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "W1, b1, W2, b2 = train(X, y.reshape(-1, 1), input_dim, hidden_dim, output_dim, epochs, learning_rate, activation='relu')\n",
    "\n",
    "# 测试模型\n",
    "y_pred = predict(X, W1, b1, W2, b2, activation='relu')\n",
    "accuracy = np.mean(y_pred == y)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
